{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import codecs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path_3 = '/home/pengfei/data/PDTB-3.0/data/raw/'\n",
    "raw_data_path_2 = '/home/pengfei/data/2015-2016_conll_shared_task/raw'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_3 = os.listdir(raw_data_path_3)\n",
    "folder_2 = os.listdir(raw_data_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_3 = set([filename for folder in folder_3 for filename in os.listdir(raw_data_path_3 + folder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2 = set(folder_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_2 - file_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_3 - file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_2 - file_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion:\n",
    "conll version does not contain 00, 01, and 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data_path_3 = '/home/pengfei/data/PDTB-3.0/data/gold/'\n",
    "gold_data_path_2 = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-train/pdtb-parses.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_3 = os.listdir(gold_data_path_3)\n",
    "file_3 = set([filename for folder in folder_3 for filename in os.listdir(gold_data_path_3 + folder)])\n",
    "parse_dict = json.loads(codecs.open(gold_data_path_2, encoding='utf-8', errors='ignore').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = set(parse_dict.keys())\n",
    "file3 = file_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion:\n",
    "file3 contain files that is not in file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(o[4:6] for o in (file2 - file3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00', '01', '09', '12', '13', '22', '23', '24'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(o[4:6] for o in (file3 - file2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsj_1344\n",
      "wsj_0998\n",
      "wsj_1202\n"
     ]
    }
   ],
   "source": [
    "for o in file3-file2:\n",
    "    if o[4:6] in ['09', '12', '13']:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdtb study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Relation_Type</th>\n",
       "      <th>Conn_SpanList</th>\n",
       "      <th>Conn_Src</th>\n",
       "      <th>Conn_Type</th>\n",
       "      <th>Conn_Pol</th>\n",
       "      <th>Conn_Det</th>\n",
       "      <th>Conn_Feat_SpanList</th>\n",
       "      <th>Conn1</th>\n",
       "      <th>SClass1A</th>\n",
       "      <th>...</th>\n",
       "      <th>Arg2_Det</th>\n",
       "      <th>Arg2_Feat_SpanList</th>\n",
       "      <th>Sup2_SpanList</th>\n",
       "      <th>Adju_Reason</th>\n",
       "      <th>Adju_Disagr</th>\n",
       "      <th>PB_Role</th>\n",
       "      <th>PB_Verb</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Provenance</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>EntRel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166</td>\n",
       "      <td>PDTB2::wsj_0793::166::SAME</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Explicit</td>\n",
       "      <td>197..204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>instead</td>\n",
       "      <td>Expansion.Substitution.Arg2-as-subst</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197..204</td>\n",
       "      <td>PDTB2::wsj_0793::197..204::CHANGED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>then</td>\n",
       "      <td>Temporal.Asynchronous.Precedence</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>PDTB3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as a result</td>\n",
       "      <td>Contingency.Cause.Result</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>333</td>\n",
       "      <td>PDTB2::wsj_0793::333::SAME</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>but</td>\n",
       "      <td>Comparison.Concession.Arg2-as-denier</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>740</td>\n",
       "      <td>PDTB2::wsj_0793::740::CHANGED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DocID Relation_Type Conn_SpanList  Conn_Src  Conn_Type  Conn_Pol  \\\n",
       "0  wsj_0793        EntRel           NaN       NaN        NaN       NaN   \n",
       "1  wsj_0793      Explicit      197..204       NaN        NaN       NaN   \n",
       "2  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "3  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "4  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "\n",
       "   Conn_Det Conn_Feat_SpanList        Conn1  \\\n",
       "0       NaN                NaN          NaN   \n",
       "1       NaN                NaN      instead   \n",
       "2       NaN                NaN         then   \n",
       "3       NaN                NaN  as a result   \n",
       "4       NaN                NaN          but   \n",
       "\n",
       "                               SClass1A  ... Arg2_Det Arg2_Feat_SpanList  \\\n",
       "0                                   NaN  ...      NaN                NaN   \n",
       "1  Expansion.Substitution.Arg2-as-subst  ...      NaN                NaN   \n",
       "2      Temporal.Asynchronous.Precedence  ...      NaN                NaN   \n",
       "3              Contingency.Cause.Result  ...      NaN                NaN   \n",
       "4  Comparison.Concession.Arg2-as-denier  ...      NaN                NaN   \n",
       "\n",
       "  Sup2_SpanList  Adju_Reason Adju_Disagr PB_Role  PB_Verb    Offset  \\\n",
       "0           NaN          NaN         NaN     NaN      NaN       166   \n",
       "1           NaN          NaN         NaN     NaN      NaN  197..204   \n",
       "2           NaN          NaN         NaN     NaN      NaN       281   \n",
       "3           NaN          NaN         NaN     NaN      NaN       333   \n",
       "4           NaN          NaN         NaN     NaN      NaN       740   \n",
       "\n",
       "                           Provenance  Link  \n",
       "0          PDTB2::wsj_0793::166::SAME   NaN  \n",
       "1  PDTB2::wsj_0793::197..204::CHANGED   NaN  \n",
       "2                               PDTB3   NaN  \n",
       "3          PDTB2::wsj_0793::333::SAME   NaN  \n",
       "4       PDTB2::wsj_0793::740::CHANGED   NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdtb3 = pd.read_csv('pdtb3.csv')\n",
    "pdtb3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Implicit', 'EntRel', 'NoRel', 'Hypophora', 'AltLexC', 'AltLex', 'Explicit'}\n",
      "Index(['Relation_Type', 'Conn_SpanList', 'Conn_Src', 'Conn_Type', 'Conn_Pol',\n",
      "       'Conn_Det', 'Conn_Feat_SpanList', 'Conn1', 'SClass1A', 'SClass1B',\n",
      "       'Conn2', 'SClass2A', 'SClass2B', 'Sup1_SpanList', 'Arg1_SpanList',\n",
      "       'Arg1_Src', 'Arg1_Type', 'Arg1_Pol', 'Arg1_Det', 'Arg2_Feat_SpanList',\n",
      "       'Arg2_SpanList', 'Arg2_Src', 'Arg2_Type', 'Arg2_Pol', 'Arg2_Det',\n",
      "       'Arg2_Feat_SpanList.1', 'Sup2_SpanList', 'Adju_Reason', 'Adju_Disagr',\n",
      "       'PB_Role', 'PB_Verb', 'Offset', 'Provenance', 'Link'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "Type = []\n",
    "for i in range(len(pdtb3)):\n",
    "    Type.append(pdtb3.loc[i, 'Relation_Type'])\n",
    "print(set(Type)), \n",
    "print(pdtb3.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) != float)\n",
    "        assert(type(pdtb3.loc[i, 'Arg1_SpanList']) != float)\n",
    "        assert(type(pdtb3.loc[i, 'Arg2_SpanList']) != float)\n",
    "        assert(type(pdtb3.loc[i, 'Conn1']) != float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'AltLex':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) != float)\n",
    "        assert(type(pdtb3.loc[i, 'Conn1']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'AltLexC':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) != float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Implicit':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'EntRel':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'NoRel':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Hypophora':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 LINK1\n"
     ]
    }
   ],
   "source": [
    "check = 'Link'\n",
    "for i in range(len(pdtb3)):\n",
    "    if not (type(pdtb3.loc[i, check]) == np.float64 or type(pdtb3.loc[i, check]) == float): \n",
    "        print(i, pdtb3.loc[i, check])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for conn span list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrect conn span list 81\n"
     ]
    }
   ],
   "source": [
    "main_folder = '/home/pengfei/data/PDTB-3.0/all/raw/'\n",
    "count = 0\n",
    "def get_span_list(span):\n",
    "    if span == '':\n",
    "        assert(False)\n",
    "    spans = span.split(';')\n",
    "    return [[int(k) for k in o.split('..')] for o in spans if o != '']\n",
    "\n",
    "\n",
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit':\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Conn_SpanList'])\n",
    "        with open(main_folder + pdtb3.loc[i, 'DocID']) as f:\n",
    "            rawtext = f.read()\n",
    "            expected = ' '.join([rawtext[o[0]: o[1]] for o in spanlist]).lower()\n",
    "        if pdtb3.loc[i, 'Conn1'] not in expected:\n",
    "            # print(pdtb3.loc[i, 'Conn1'], i, pdtb3.loc[i, 'DocID'], expected)\n",
    "            count+=1\n",
    "            \n",
    "print(\"Number of incorrect conn span list\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check all the explicit connectives is in the connectives list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Arg1 spanlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "907 wsj_0776 [[4279, 4367]]\n",
      "908 wsj_0776 [[4246, 4367]]\n",
      "1399 wsj_0786 [[9, 102]]\n",
      "2560 wsj_0597 [[9, 253]]\n",
      "2695 wsj_0575 [[9, 26], [81, 155]]\n",
      "2978 wsj_0567 [[9, 223]]\n",
      "3439 wsj_0557 [[1740, 1826]]\n",
      "4167 wsj_0589 [[5074, 5163]]\n",
      "6801 wsj_0240 [[2059, 2148]]\n",
      "6802 wsj_0240 [[2059, 2148]]\n",
      "7113 wsj_0296 [[3690, 3724]]\n",
      "7263 wsj_0245 [[1726, 1797]]\n",
      "7707 wsj_0284 [[9, 199]]\n",
      "13254 wsj_2071 [[43, 125]]\n",
      "13593 wsj_2086 [[1210, 1301]]\n",
      "13602 wsj_2086 [[1885, 2069]]\n",
      "14434 wsj_2070 [[3345, 3351], [3375, 3379], [3442, 3541]]\n",
      "14605 wsj_2013 [[18326, 18432]]\n",
      "14992 wsj_1515 [[4067, 4164]]\n",
      "14993 wsj_1515 [[4067, 4164], [4237, 4281]]\n",
      "15372 wsj_1554 [[2004, 2076]]\n",
      "15526 wsj_1586 [[2966, 3008]]\n",
      "15527 wsj_1586 [[2966, 3008]]\n",
      "16210 wsj_1572 [[3082, 3130]]\n",
      "17249 wsj_0938 [[2601, 2710]]\n",
      "18864 wsj_0910 [[474, 594]]\n",
      "18871 wsj_0910 [[1660, 1721]]\n",
      "19267 wsj_0956 [[3767, 3844]]\n",
      "20513 wsj_0400 [[6755, 6914]]\n",
      "20584 wsj_0448 [[427, 518]]\n",
      "21333 wsj_0435 [[1938, 2045]]\n",
      "21581 wsj_0445 [[1180, 1344]]\n",
      "21648 wsj_0445 [[6490, 6570]]\n",
      "21680 wsj_0445 [[8609, 8665]]\n",
      "21686 wsj_0445 [[9078, 9133]]\n",
      "22019 wsj_1473 [[231, 280]]\n",
      "22089 wsj_1410 [[3504, 3706]]\n",
      "22194 wsj_1404 [[503, 573]]\n",
      "24086 wsj_1492 [[887, 1000]]\n",
      "24315 wsj_1735 [[886, 928]]\n",
      "24367 wsj_1754 [[721, 806]]\n",
      "24778 wsj_1744 [[2042, 2096]]\n",
      "25787 wsj_1787 [[207, 270]]\n",
      "25927 wsj_1794 [[1778, 1899]]\n",
      "26258 wsj_1986 [[1526, 1603]]\n",
      "26771 wsj_1992 [[9, 33], [129, 195]]\n",
      "26811 wsj_1903 [[2282, 2378]]\n",
      "26928 wsj_1916 [[2055, 2103]]\n",
      "27507 wsj_1915 [[4887, 4960]]\n",
      "27619 wsj_1924 [[2067, 2137]]\n",
      "28120 wsj_1249 [[2031, 2066]]\n",
      "28159 wsj_1289 [[44, 125]]\n",
      "28446 wsj_1247 [[328, 391]]\n",
      "28588 wsj_1255 [[324, 430]]\n",
      "28604 wsj_1234 [[389, 478]]\n",
      "28692 wsj_1248 [[9, 201]]\n",
      "28796 wsj_1225 [[3571, 3694]]\n",
      "29023 wsj_1201 [[2573, 2655]]\n",
      "29290 wsj_1274 [[1074, 1159]]\n",
      "29975 wsj_1250 [[4467, 4577]]\n",
      "32723 wsj_1044 [[4271, 4456]]\n",
      "32833 wsj_1048 [[9, 91]]\n",
      "32998 wsj_1037 [[2494, 2572]]\n",
      "33772 wsj_1057 [[3409, 3446]]\n",
      "34426 wsj_2172 [[23, 97]]\n",
      "34743 wsj_2106 [[4027, 4124]]\n",
      "35444 wsj_2105 [[426, 472]]\n",
      "35968 wsj_2112 [[4558, 4646]]\n",
      "38694 wsj_1125 [[530, 658], [1024, 1253]]\n",
      "38872 wsj_1377 [[1811, 1849]]\n",
      "38898 wsj_1377 [[3770, 3871]]\n",
      "39178 wsj_1363 [[291, 393]]\n",
      "39507 wsj_1373 [[4511, 4565]]\n",
      "39538 wsj_1372 [[1491, 1631]]\n",
      "39568 wsj_1303 [[1991, 2055]]\n",
      "40514 wsj_1318 [[1135, 1169]]\n",
      "40515 wsj_1318 [[1135, 1169]]\n",
      "40537 wsj_1341 [[394, 401], [439, 473]]\n",
      "40545 wsj_1310 [[9, 134]]\n",
      "42489 wsj_1641 [[9, 96]]\n",
      "42551 wsj_1618 [[1381, 1500]]\n",
      "44034 wsj_1630 [[9, 29], [125, 187]]\n",
      "44951 wsj_0367 [[4803, 4820], [4937, 4979]]\n",
      "45320 wsj_0338 [[655, 736]]\n",
      "45553 wsj_0322 [[9, 70]]\n",
      "46158 wsj_0328 [[9, 101]]\n",
      "46180 wsj_0328 [[9, 241]]\n",
      "46192 wsj_0328 [[4423, 4604]]\n",
      "50226 wsj_1830 [[2270, 2273], [2340, 2380]]\n",
      "50717 wsj_1855 [[1179, 1356]]\n",
      "the number of Arg1 error 90\n"
     ]
    }
   ],
   "source": [
    "gold_data_path_2 = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-train/pdtb-parses.json'\n",
    "parse_dict = json.loads(codecs.open(gold_data_path_2, encoding='utf-8', errors='ignore').read())\n",
    "def get_list(parse_dict, doc):\n",
    "    doc = parse_dict[doc]['sentences']\n",
    "    char_start_list = []\n",
    "    char_end_list = []\n",
    "    for sentence in doc:\n",
    "        for word in sentence['words']:\n",
    "            char_start_list.append(word[1]['CharacterOffsetBegin'])\n",
    "            char_end_list.append(word[1]['CharacterOffsetEnd'])\n",
    "    return char_start_list, char_end_list\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit' and pdtb3.loc[i, 'DocID'] in parse_dict.keys():\n",
    "        char_start_list, char_end_list = get_list(parse_dict, pdtb3.loc[i, 'DocID'])\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Arg1_SpanList'])\n",
    "        for span in spanlist:\n",
    "            if not ((span[0] in char_start_list) and (span[1] in char_end_list)):\n",
    "                count += 1\n",
    "#                 print(i, pdtb3.loc[i, 'DocID'], spanlist)\n",
    "#         with open(main_folder + pdtb3.loc[i, 'DocID']) as f:\n",
    "#             rawtext = f.read()\n",
    "#             expected = ' '.join([rawtext[o[0]: o[1]] for o in spanlist]).lower()\n",
    "print(\"the number of Arg1 error\", count)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for arg2 spanlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of Arg1 error 77\n"
     ]
    }
   ],
   "source": [
    "gold_data_path_2 = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-train/pdtb-parses.json'\n",
    "parse_dict = json.loads(codecs.open(gold_data_path_2, encoding='utf-8', errors='ignore').read())\n",
    "def get_list(parse_dict, doc):\n",
    "    doc = parse_dict[doc]['sentences']\n",
    "    char_start_list = []\n",
    "    char_end_list = []\n",
    "    for sentence in doc:\n",
    "        for word in sentence['words']:\n",
    "            char_start_list.append(word[1]['CharacterOffsetBegin'])\n",
    "            char_end_list.append(word[1]['CharacterOffsetEnd'])\n",
    "    return char_start_list, char_end_list\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit' and pdtb3.loc[i, 'DocID'] in parse_dict.keys():\n",
    "        char_start_list, char_end_list = get_list(parse_dict, pdtb3.loc[i, 'DocID'])\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Arg2_SpanList'])\n",
    "        for span in spanlist:\n",
    "            if not ((span[0] in char_start_list) and (span[1] in char_end_list)):\n",
    "                count += 1\n",
    "#                 print(i, pdtb3.loc[i, 'DocID'], spanlist)\n",
    "\n",
    "print(\"the number of Arg1 error\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
