{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(parse_dict, doc):\n",
    "    doc = parse_dict[doc]['sentences']\n",
    "    char_start_list = []\n",
    "    char_end_list = []\n",
    "    for sentence in doc:\n",
    "        for word in sentence['words']:\n",
    "            char_start_list.append(word[1]['CharacterOffsetBegin'])\n",
    "            char_end_list.append(word[1]['CharacterOffsetEnd'])\n",
    "    return char_start_list, char_end_list\n",
    "\n",
    "\n",
    "def get_span_string(span_list):\n",
    "    ret = ''\n",
    "    for span in span_list:\n",
    "        ret += str(span[0])\n",
    "        ret += '..'\n",
    "        ret += str(span[1])\n",
    "        ret += ';'\n",
    "    return ret[:-1]\n",
    "\n",
    "def get_span_list(span):\n",
    "    if span == '':\n",
    "        assert(False)\n",
    "    spans = span.split(';')\n",
    "    return [[int(k) for k in o.split('..')] for o in spans if o != '']\n",
    "\n",
    "def get_doc_word_dict(parse_dict, DocID):\n",
    "    ret={}\n",
    "    doc_token_index = 0\n",
    "    for sent_index, sentence in enumerate(parse_dict[DocID]['sentences']):\n",
    "        for token_index, token in enumerate(sentence['words']):\n",
    "            start = token[1]['CharacterOffsetBegin']\n",
    "            end = token[1]['CharacterOffsetEnd']\n",
    "            ret[(start, end)] = [start, end, doc_token_index, sent_index, token_index]\n",
    "            doc_token_index += 1\n",
    "    return ret\n",
    "\n",
    "def get_token_list(char_span_list, doc_word_dict):\n",
    "    tokenlist = []\n",
    "    doc_word_dict = OrderedDict(sorted(doc_word_dict.items()), keys=lambda x:x[0][0])\n",
    "    for span in char_span_list:\n",
    "        for key, value in doc_word_dict.items():\n",
    "            if key[1] <= span[1]:\n",
    "                break\n",
    "            if key[0] >= span[0]:\n",
    "                tokenlist.append(value)\n",
    "    return tokenlist\n",
    "\n",
    "def merge3dicts(x, y, z):\n",
    "    m = x\n",
    "    m.update(y)\n",
    "    m.update(z)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Relation_Type</th>\n",
       "      <th>Conn_SpanList</th>\n",
       "      <th>Conn_Src</th>\n",
       "      <th>Conn_Type</th>\n",
       "      <th>Conn_Pol</th>\n",
       "      <th>Conn_Det</th>\n",
       "      <th>Conn_Feat_SpanList</th>\n",
       "      <th>Conn1</th>\n",
       "      <th>SClass1A</th>\n",
       "      <th>...</th>\n",
       "      <th>Arg2_Det</th>\n",
       "      <th>Arg2_Feat_SpanList</th>\n",
       "      <th>Sup2_SpanList</th>\n",
       "      <th>Adju_Reason</th>\n",
       "      <th>Adju_Disagr</th>\n",
       "      <th>PB_Role</th>\n",
       "      <th>PB_Verb</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Provenance</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>EntRel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166</td>\n",
       "      <td>PDTB2::wsj_0793::166::SAME</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Explicit</td>\n",
       "      <td>197..204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>instead</td>\n",
       "      <td>Expansion.Substitution.Arg2-as-subst</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197..204</td>\n",
       "      <td>PDTB2::wsj_0793::197..204::CHANGED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>then</td>\n",
       "      <td>Temporal.Asynchronous.Precedence</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>PDTB3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as a result</td>\n",
       "      <td>Contingency.Cause.Result</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>333</td>\n",
       "      <td>PDTB2::wsj_0793::333::SAME</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>but</td>\n",
       "      <td>Comparison.Concession.Arg2-as-denier</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>740</td>\n",
       "      <td>PDTB2::wsj_0793::740::CHANGED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DocID Relation_Type Conn_SpanList  Conn_Src  Conn_Type  Conn_Pol  \\\n",
       "0  wsj_0793        EntRel           NaN       NaN        NaN       NaN   \n",
       "1  wsj_0793      Explicit      197..204       NaN        NaN       NaN   \n",
       "2  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "3  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "4  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "\n",
       "   Conn_Det Conn_Feat_SpanList        Conn1  \\\n",
       "0       NaN                NaN          NaN   \n",
       "1       NaN                NaN      instead   \n",
       "2       NaN                NaN         then   \n",
       "3       NaN                NaN  as a result   \n",
       "4       NaN                NaN          but   \n",
       "\n",
       "                               SClass1A  ... Arg2_Det Arg2_Feat_SpanList  \\\n",
       "0                                   NaN  ...      NaN                NaN   \n",
       "1  Expansion.Substitution.Arg2-as-subst  ...      NaN                NaN   \n",
       "2      Temporal.Asynchronous.Precedence  ...      NaN                NaN   \n",
       "3              Contingency.Cause.Result  ...      NaN                NaN   \n",
       "4  Comparison.Concession.Arg2-as-denier  ...      NaN                NaN   \n",
       "\n",
       "  Sup2_SpanList  Adju_Reason Adju_Disagr PB_Role  PB_Verb    Offset  \\\n",
       "0           NaN          NaN         NaN     NaN      NaN       166   \n",
       "1           NaN          NaN         NaN     NaN      NaN  197..204   \n",
       "2           NaN          NaN         NaN     NaN      NaN       281   \n",
       "3           NaN          NaN         NaN     NaN      NaN       333   \n",
       "4           NaN          NaN         NaN     NaN      NaN       740   \n",
       "\n",
       "                           Provenance  Link  \n",
       "0          PDTB2::wsj_0793::166::SAME   NaN  \n",
       "1  PDTB2::wsj_0793::197..204::CHANGED   NaN  \n",
       "2                               PDTB3   NaN  \n",
       "3          PDTB2::wsj_0793::333::SAME   NaN  \n",
       "4       PDTB2::wsj_0793::740::CHANGED   NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdtb3 = pd.read_csv('pdtb3.csv')\n",
    "pdtb3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets loaded\n"
     ]
    }
   ],
   "source": [
    "conll_train = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-train/pdtb-parses.json'\n",
    "parse_dict_train = json.loads(codecs.open(conll_train, encoding='utf-8', errors='ignore').read())\n",
    "conll_dev = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-dev/pdtb-parses.json'\n",
    "parse_dict_dev = json.loads(codecs.open(conll_dev, encoding='utf-8', errors='ignore').read())\n",
    "conll_test = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-test/pdtb-parses.json'\n",
    "parse_dict_test = json.loads(codecs.open(conll_test, encoding='utf-8', errors='ignore').read())\n",
    "print(\"datasets loaded\")\n",
    "parse_dict = merge3dicts(parse_dict_train, parse_dict_dev, parse_dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtext_foldername = Path('/home/pengfei/data/PDTB-3.0/all/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n"
     ]
    }
   ],
   "source": [
    "relations = []\n",
    "unattended = []\n",
    "for i in range(len(pdtb3)):\n",
    "    if i%1000 == 0:print(i)\n",
    "    if pdtb3.loc[i,'DocID'] not in parse_dict.keys(): continue;unattended.append(pdtb3.loc[i,'DocID'])\n",
    "    relation = {}\n",
    "\n",
    "    relation['DocID'] = pdtb3.loc[i, 'DocID']\n",
    "\n",
    "    relation['ID'] = i\n",
    "\n",
    "    Sense = [pdtb3.loc[i,'SClass1A']]\n",
    "    if type(pdtb3.loc[i,'SClass1B']) != float: Sense.append(pdtb3.loc[i,'SClass1B'])\n",
    "    if type(pdtb3.loc[i,'SClass2A']) != float: Sense.append(pdtb3.loc[i,'SClass2A'])\n",
    "    if type(pdtb3.loc[i,'SClass2B']) != float: Sense.append(pdtb3.loc[i,'SClass2B'])\n",
    "    relation['Sense'] = Sense\n",
    "\n",
    "    relation['Type'] = pdtb3.loc[i, 'Relation_Type']\n",
    "\n",
    "    doc_word_dict = get_doc_word_dict(parse_dict, pdtb3.loc[i, 'DocID'])\n",
    "    rawtext = codecs.open(rawtext_foldername/pdtb3.loc[i,'DocID'], encoding='utf-8', errors='ignore').read()\n",
    "\n",
    "    # connective\n",
    "    relation['Connective'] = {}\n",
    "    if relation['Type'] in ['Explicit', 'AltLex', 'AltLexC']:\n",
    "        relation['Connective']['CharacterSpanList'] = get_span_list(pdtb3.loc[i, 'Conn_SpanList'])\n",
    "        relation['Connective']['RawText'] = pdtb3.loc[i, 'Conn1']\n",
    "        relation['Connective']['TokenList'] = get_token_list(relation['Connective']['CharacterSpanList'], doc_word_dict)\n",
    "    else:\n",
    "        relation['Connective']['CharacterSpanList'] = []\n",
    "        relation['Connective']['RawText'] = pdtb3.loc[i, 'Conn1']\n",
    "\n",
    "    # Arg1\n",
    "    relation['Arg1'] = {}\n",
    "    char_span_list = get_span_list(pdtb3.loc[i,'Arg1_SpanList'])\n",
    "    relation['Arg1']['CharacterSpanList'] = char_span_list\n",
    "    arg_rawtext = ' '.join([rawtext[o[0]:o[1]] for o in char_span_list])\n",
    "    relation['Arg1']['RawText'] = arg_rawtext\n",
    "    arg_tokenlist = get_token_list(char_span_list, doc_word_dict)\n",
    "    relation['Arg1']['TokenList'] = arg_tokenlist\n",
    "\n",
    "    # Arg2\n",
    "    relation['Arg2'] = {}\n",
    "    char_span_list = get_span_list(pdtb3.loc[i,'Arg2_SpanList'])\n",
    "    relation['Arg2']['CharacterSpanList'] = char_span_list\n",
    "    arg_rawtext = ' '.join([rawtext[o[0]:o[1]] for o in char_span_list])\n",
    "    relation['Arg2']['RawText'] = arg_rawtext\n",
    "    arg_tokenlist = get_token_list(char_span_list, doc_word_dict)\n",
    "    relation['Arg2']['TokenList'] = arg_tokenlist\n",
    "\n",
    "    relations.append(relation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
