{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import json\n",
    "import codecs\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path_3 = '/home/pengfei/data/PDTB-3.0/data/raw/'\n",
    "raw_data_path_2 = '/home/pengfei/data/2015-2016_conll_shared_task/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_3 = os.listdir(raw_data_path_3)\n",
    "folder_2 = os.listdir(raw_data_path_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_3 = set([filename for folder in folder_3 for filename in os.listdir(raw_data_path_3 + folder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2 = set(folder_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_2 - file_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_3 - file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_2 - file_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion:\n",
    "conll version does not contain 00, 01, and 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data_path_3 = '/home/pengfei/data/PDTB-3.0/data/gold/'\n",
    "gold_data_path_2 = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-train/pdtb-parses.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_3 = os.listdir(gold_data_path_3)\n",
    "file_3 = set([filename for folder in folder_3 for filename in os.listdir(gold_data_path_3 + folder)])\n",
    "parse_dict = json.loads(codecs.open(gold_data_path_2, encoding='utf-8', errors='ignore').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = set(parse_dict.keys())\n",
    "file3 = file_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion:\n",
    "file3 contain files that is not in file2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(o[4:6] for o in (file2 - file3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00', '01', '09', '12', '13', '22', '23', '24'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(o[4:6] for o in (file3 - file2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsj_1344\n",
      "wsj_0998\n",
      "wsj_1202\n"
     ]
    }
   ],
   "source": [
    "for o in file3-file2:\n",
    "    if o[4:6] in ['09', '12', '13']:\n",
    "        print(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pdtb study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>Relation_Type</th>\n",
       "      <th>Conn_SpanList</th>\n",
       "      <th>Conn_Src</th>\n",
       "      <th>Conn_Type</th>\n",
       "      <th>Conn_Pol</th>\n",
       "      <th>Conn_Det</th>\n",
       "      <th>Conn_Feat_SpanList</th>\n",
       "      <th>Conn1</th>\n",
       "      <th>SClass1A</th>\n",
       "      <th>...</th>\n",
       "      <th>Arg2_Det</th>\n",
       "      <th>Arg2_Feat_SpanList</th>\n",
       "      <th>Sup2_SpanList</th>\n",
       "      <th>Adju_Reason</th>\n",
       "      <th>Adju_Disagr</th>\n",
       "      <th>PB_Role</th>\n",
       "      <th>PB_Verb</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Provenance</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>EntRel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166</td>\n",
       "      <td>PDTB2::wsj_0793::166::SAME</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Explicit</td>\n",
       "      <td>197..204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>instead</td>\n",
       "      <td>Expansion.Substitution.Arg2-as-subst</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197..204</td>\n",
       "      <td>PDTB2::wsj_0793::197..204::CHANGED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>then</td>\n",
       "      <td>Temporal.Asynchronous.Precedence</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281</td>\n",
       "      <td>PDTB3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>as a result</td>\n",
       "      <td>Contingency.Cause.Result</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>333</td>\n",
       "      <td>PDTB2::wsj_0793::333::SAME</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wsj_0793</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>but</td>\n",
       "      <td>Comparison.Concession.Arg2-as-denier</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>740</td>\n",
       "      <td>PDTB2::wsj_0793::740::CHANGED</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DocID Relation_Type Conn_SpanList  Conn_Src  Conn_Type  Conn_Pol  \\\n",
       "0  wsj_0793        EntRel           NaN       NaN        NaN       NaN   \n",
       "1  wsj_0793      Explicit      197..204       NaN        NaN       NaN   \n",
       "2  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "3  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "4  wsj_0793      Implicit           NaN       NaN        NaN       NaN   \n",
       "\n",
       "   Conn_Det Conn_Feat_SpanList        Conn1  \\\n",
       "0       NaN                NaN          NaN   \n",
       "1       NaN                NaN      instead   \n",
       "2       NaN                NaN         then   \n",
       "3       NaN                NaN  as a result   \n",
       "4       NaN                NaN          but   \n",
       "\n",
       "                               SClass1A  ... Arg2_Det Arg2_Feat_SpanList  \\\n",
       "0                                   NaN  ...      NaN                NaN   \n",
       "1  Expansion.Substitution.Arg2-as-subst  ...      NaN                NaN   \n",
       "2      Temporal.Asynchronous.Precedence  ...      NaN                NaN   \n",
       "3              Contingency.Cause.Result  ...      NaN                NaN   \n",
       "4  Comparison.Concession.Arg2-as-denier  ...      NaN                NaN   \n",
       "\n",
       "  Sup2_SpanList  Adju_Reason Adju_Disagr PB_Role  PB_Verb    Offset  \\\n",
       "0           NaN          NaN         NaN     NaN      NaN       166   \n",
       "1           NaN          NaN         NaN     NaN      NaN  197..204   \n",
       "2           NaN          NaN         NaN     NaN      NaN       281   \n",
       "3           NaN          NaN         NaN     NaN      NaN       333   \n",
       "4           NaN          NaN         NaN     NaN      NaN       740   \n",
       "\n",
       "                           Provenance  Link  \n",
       "0          PDTB2::wsj_0793::166::SAME   NaN  \n",
       "1  PDTB2::wsj_0793::197..204::CHANGED   NaN  \n",
       "2                               PDTB3   NaN  \n",
       "3          PDTB2::wsj_0793::333::SAME   NaN  \n",
       "4       PDTB2::wsj_0793::740::CHANGED   NaN  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdtb3 = pd.read_csv('../pdtb3.csv')\n",
    "pdtb3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Implicit', 'EntRel', 'NoRel', 'Hypophora', 'AltLexC', 'AltLex', 'Explicit'}\n",
      "Index(['Relation_Type', 'Conn_SpanList', 'Conn_Src', 'Conn_Type', 'Conn_Pol',\n",
      "       'Conn_Det', 'Conn_Feat_SpanList', 'Conn1', 'SClass1A', 'SClass1B',\n",
      "       'Conn2', 'SClass2A', 'SClass2B', 'Sup1_SpanList', 'Arg1_SpanList',\n",
      "       'Arg1_Src', 'Arg1_Type', 'Arg1_Pol', 'Arg1_Det', 'Arg2_Feat_SpanList',\n",
      "       'Arg2_SpanList', 'Arg2_Src', 'Arg2_Type', 'Arg2_Pol', 'Arg2_Det',\n",
      "       'Arg2_Feat_SpanList.1', 'Sup2_SpanList', 'Adju_Reason', 'Adju_Disagr',\n",
      "       'PB_Role', 'PB_Verb', 'Offset', 'Provenance', 'Link'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "Type = []\n",
    "for i in range(len(pdtb3)):\n",
    "    Type.append(pdtb3.loc[i, 'Relation_Type'])\n",
    "print(set(Type)), \n",
    "print(pdtb3.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) != float)\n",
    "        assert(type(pdtb3.loc[i, 'Arg1_SpanList']) != float)\n",
    "        assert(type(pdtb3.loc[i, 'Arg2_SpanList']) != float)\n",
    "        assert(type(pdtb3.loc[i, 'Conn1']) != float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'AltLex':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) != float)\n",
    "        assert(type(pdtb3.loc[i, 'Conn1']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'AltLexC':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) != float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Implicit':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'EntRel':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'NoRel':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Hypophora':\n",
    "        assert(type(pdtb3.loc[i, 'Conn_SpanList']) == float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 LINK1\n"
     ]
    }
   ],
   "source": [
    "check = 'Link'\n",
    "for i in range(len(pdtb3)):\n",
    "    if not (type(pdtb3.loc[i, check]) == np.float64 or type(pdtb3.loc[i, check]) == float): \n",
    "        print(i, pdtb3.loc[i, check])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for conn span list: number of uncorrected 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'in <string>' requires string as left operand, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-bc4f88338f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mrawtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrawtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspanlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpdtb3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Conn1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdtb3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Conn1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdtb3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DocID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mfalse_conn_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'in <string>' requires string as left operand, not float"
     ]
    }
   ],
   "source": [
    "main_folder = '/home/pengfei/data/PDTB-3.0/all/raw/'\n",
    "false_conn_list = []\n",
    "def get_span_list(span):\n",
    "    if span == '':\n",
    "        assert(False)\n",
    "    spans = span.split(';')\n",
    "    return [[int(k) for k in o.split('..')] for o in spans if o != '']\n",
    "\n",
    "\n",
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] in ['Explicit', 'AltLex', 'AltLexC']:\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Conn_SpanList'])\n",
    "        with open(main_folder + pdtb3.loc[i, 'DocID']) as f:\n",
    "            rawtext = f.read()\n",
    "            expected = ' '.join([rawtext[o[0]: o[1]] for o in spanlist]).lower()\n",
    "        if pdtb3.loc[i, 'Conn1'] not in expected:\n",
    "            print(pdtb3.loc[i, 'Conn1'], i, pdtb3.loc[i, 'DocID'], expected)\n",
    "            false_conn_list.append(i)\n",
    "            \n",
    "print(\"Number of incorrect conn span list\", len(false_conn_list))\n",
    "\n",
    "# for i in false_conn_list:\n",
    "#     with open(main_folder+pdtb3.loc[i,'DocID']) as f:\n",
    "#         rawtext = f.read().lower()\n",
    "#         start = int(pdtb3.loc[i, 'Conn_SpanList'].split('..')[0])\n",
    "#         distance = [abs(m.start() - start) for m in re.finditer(pdtb3.loc[i,'Conn1'], rawtext, )]\n",
    "#         start = [m.start() for m in re.finditer(pdtb3.loc[i, 'Conn1'], rawtext)]\n",
    "#         if distance != []:\n",
    "#             index = distance.index(min(distance))\n",
    "#             start = start[index]\n",
    "#             span = str(start) + '..' + str(start+len(pdtb3.loc[i, 'Conn1']))\n",
    "#             pdtb3.loc[i, 'Conn_SpanList'] = span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = '/home/pengfei/data/PDTB-3.0/data/raw/'\n",
    "write_folder = '/home/pengfei/data/PDTB-3.0/all/raw/'\n",
    "filepaths = [main_folder+folder+'/'+o for folder in os.listdir(main_folder) for o in os.listdir(main_folder+folder)]\n",
    "for file in filepaths:\n",
    "    with open(file, encoding='latin1') as f:\n",
    "        rawtext = f.read()\n",
    "    with open(write_folder + file.split('/')[-1], 'a') as f:\n",
    "        f.write(rawtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check all the explicit connectives is in the connectives list\n",
    "yes they are in the list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check all raw data doesn't change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdtb2 vs pdtb3\n",
    "main_folder = Path('/home/pengfei/data/pdtb_v2/all/raw')\n",
    "filenames = [o for o in os.listdir(main_folder)]\n",
    "pdtb2_raw_folder = main_folder\n",
    "pdtb3_raw_folder = Path('/home/pengfei/data/PDTB-3.0/all/raw')\n",
    "\n",
    "raw_false = []\n",
    "for filename in filenames:\n",
    "    with open(pdtb2_raw_folder/filename) as f:\n",
    "        raw2 = f.read()\n",
    "    with open(pdtb3_raw_folder/filename) as f:\n",
    "        raw3 = f.read()\n",
    "    if raw2 != raw3:\n",
    "        raw_false.append(filename)\n",
    "#         print(raw2.replace('\\n', ''))\n",
    "#         print()\n",
    "#         print(raw3.replace('\\n', ''))\n",
    "#         print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw data does change adding space dot and \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conll vs pdtb3\n",
    "main_folder = Path('/home/pengfei/data/2015-2016_conll_shared_task/raw')\n",
    "filenames = [o for o in os.listdir(main_folder)]\n",
    "pdtb2_raw_folder = main_folder\n",
    "pdtb3_raw_folder = Path('/home/pengfei/data/PDTB-3.0/all/raw')\n",
    "\n",
    "raw_false = []\n",
    "for filename in filenames:\n",
    "    raw2 = codecs.open(pdtb2_raw_folder/filename, encoding='utf-8',errors='ignore').read()\n",
    "    if filename not in os.listdir(pdtb3_raw_folder):\n",
    "        continue\n",
    "    with open(pdtb3_raw_folder/filename) as f:\n",
    "        raw3 = f.read()\n",
    "    if raw2 != raw3:\n",
    "        raw_false.append(filename)\n",
    "#         print(raw2.replace('\\n', ''))\n",
    "#         print()\n",
    "#         print(raw3.replace('\\n', ''))\n",
    "#         print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Arg1 spanlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data_path_2 = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-train/pdtb-parses.json'\n",
    "parse_dict = json.loads(codecs.open(gold_data_path_2, encoding='utf-8', errors='ignore').read())\n",
    "main_folder = '/home/pengfei/data/PDTB-3.0/all/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def get_list(parse_dict, doc):\n",
    "    doc = parse_dict[doc]['sentences']\n",
    "    char_start_list = []\n",
    "    char_end_list = []\n",
    "    for sentence in doc:\n",
    "        for word in sentence['words']:\n",
    "            char_start_list.append(word[1]['CharacterOffsetBegin'])\n",
    "            char_end_list.append(word[1]['CharacterOffsetEnd'])\n",
    "    return char_start_list, char_end_list\n",
    "\n",
    "\n",
    "def get_span_string(span_list):\n",
    "    ret = ''\n",
    "    for span in span_list:\n",
    "        ret += str(span[0])\n",
    "        ret += '..'\n",
    "        ret += str(span[1])\n",
    "        ret += ';'\n",
    "    return ret[:-1]\n",
    "\n",
    "doc_list = []\n",
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit' and pdtb3.loc[i, 'DocID'] in parse_dict.keys():\n",
    "        char_start_list, char_end_list = get_list(parse_dict, pdtb3.loc[i, 'DocID'])\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Arg1_SpanList'])\n",
    "        for span in spanlist:\n",
    "            if not ((span[0] in char_start_list) and (span[1] in char_end_list)):\n",
    "                doc_list.append(min([abs(span[0]-o) for o in char_start_list]))\n",
    "\n",
    "print(max(doc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the difference between corrected and not corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industrial buyers in Europe have the opportunity of getting reasonable prices in the U.S\n",
      "industrial buyers in Europe have the opportunity of getting reasonable prices in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "If prices in the States go down, industrial buyers in Europe have the opportunity of getting reasonable prices in the U.S\n",
      "If prices in the States go down, industrial buyers in Europe have the opportunity of getting reasonable prices in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "IMA Holdings Corp. completed its $3 billion acquisition of American Medical International Inc\n",
      "IMA Holdings Corp. completed its $3 billion acquisition of American Medical International Inc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A state trial judge in Illinois gave preliminary approval to a proposed settlement of a suit against a Bank of New York Co. unit, Irving Trust Co., over the interest rates on Irving's former One Wall Street Account money-market deposit accounts\n",
      "state trial judge in Illinois gave preliminary approval to a proposed settlement of a suit against a Bank of New York Co. unit, Irving Trust Co., over the interest rates on Irving's former One Wall Street Account money-market deposit accounts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Control Data Corp thinks it will be healthy enough soon to consider repurchasing public debt\n",
      "Control Data Corp. thinks it will be healthy enough soon to consider repurchasing public debt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A two-day meeting of representatives of Cocom, the 17-nation group that oversees exports of sensitive goods to communist countries, didn't take any substantive decisions on trimming the list of items under controls\n",
      "two-day meeting of representatives of Cocom, the 17-nation group that oversees exports of sensitive goods to communist countries, didn't take any substantive decisions on trimming the list of items under controls\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Baby Ruth and Butterfinger are both among the top-selling 15 chocolate bars in the U.S\n",
      "Baby Ruth and Butterfinger are both among the top-selling 15 chocolate bars in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Estee Lauder, for example, spends only an estimated 5% of sales on advertising in the U.S\n",
      "Estee Lauder, for example, spends only an estimated 5% of sales on advertising in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Germany's trade surplus is largely with other European countries rather than with the U.S\n",
      "Germany's trade surplus is largely with other European countries rather than with the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Germany's trade surplus is largely with other European countries rather than with the U.S\n",
      "Germany's trade surplus is largely with other European countries rather than with the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the Japanese are making in the U.S\n",
      "the Japanese are making in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In Singapore, per-capita consumption is about one-third that of the U.S\n",
      "In Singapore, per-capita consumption is about one-third that of the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A federal judge ruled that Imelda Marcos wasn't brought to the U.S. against her will and that marital privileges, which protect spouses from incriminating each other, don't apply in her case\n",
      "federal judge ruled that Imelda Marcos wasn't brought to the U.S. against her will and that marital privileges, which protect spouses from incriminating each other, don't apply in her case\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it settled a four-year-old patent infringement case against Linear Technology Corp\n",
      "it settled a four-year-old patent infringement case against Linear Technology Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jaguar's ADRs make the company one of the most widely held United Kingdom stocks in the U.S\n",
      "Jaguar's ADRs make the company one of the most widely held United Kingdom stocks in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Both Shearson's Mr. Will and Stephen Reitman, European auto analyst at the London brokerage firm UBS-Phillips & Drew, recently switched their Jaguar recommendations to hold from buy\n",
      ". \n",
      "\n",
      "Both Shearson's Mr. Will and Stephen Reitman, European auto analyst at the London brokerage firm UBS-Phillips & Drew, recently switched their Jaguar recommendations to hold from buy\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "But that it nevertheless sends a clear signal that, at least for now, the Fed has relaxed its grip on credit\n",
      ". \n",
      "\n",
      "But that it nevertheless sends a clear signal that, at least for now, the Fed has relaxed its grip on credit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "He then ousted President Nicholas Ardito Barletta, a former World Bank official with close ties to the U.S\n",
      "He then ousted President Nicholas Ardito Barletta, a former World Bank official with close ties to the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Trelleborg isn't in the same league yet as mining giants such as RTZ Corp. or Anglo-American Corp\n",
      "Trelleborg isn't in the same league yet as mining giants such as RTZ Corp. or Anglo-American Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Trelleborg isn't in the same league yet as mining giants such as RTZ Corp. or Anglo-American Corp But we certainly like what we've seen so far\n",
      "Trelleborg isn't in the same league yet as mining giants such as RTZ Corp. or Anglo-American Corp. But we certainly like what we've seen so far\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A further decline in prices will lead to mine production cuts in the U.S\n",
      "A further decline in prices will lead to mine production cuts in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "he still makes most of his furs in the U.S\n",
      "he still makes most of his furs in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "he still makes most of his furs in the U.S\n",
      "he still makes most of his furs in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "that he had a secret agreement with Amoco Oil Co\n",
      "that he had a secret agreement with Amoco Oil Co.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "to buy for $57 million and then lease back to Cineplex its 18-screen theater complex in Universal City, Calif\n",
      "to buy for $57 million and then lease back to Cineplex its 18-screen theater complex in Universal City, Calif.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Latin American countries have long urged Canada to join the OAS in the hopes that it would be a counterweight to the U.S\n",
      "Latin American countries have long urged Canada to join the OAS in the hopes that it would be a counterweight to the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Canada, at times, could be an awkward OAS partner for the U.S\n",
      "Canada, at times, could be an awkward OAS partner for the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "It is rumored to be bound for a new model in the luxury Acura line in the U.S\n",
      "It is rumored to be bound for a new model in the luxury Acura line in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In the new-issue market for junk securities, underwriters at Salomon Brothers Inc. are expected to price today a $350 million junk bond offering by Beatrice Co\n",
      "In the new-issue market for junk securities, underwriters at Salomon Brothers Inc. are expected to price today a $350 million junk bond offering by Beatrice Co.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The tab even covers $8 million in commitment fees owed to Citicorp and Chase Manhattan Corp\n",
      "The tab even covers $8 million in commitment fees owed to Citicorp and Chase Manhattan Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The Japanese-managed plants eventually will have the capacity to build some 2.5 million vehicles in the U.S\n",
      "The Japanese-managed plants eventually will have the capacity to build some 2.5 million vehicles in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Combined PC and work-station use in Japan will jump as much as 25% annually over the next five years, according to some analysts, compared with about 10% in the U.S\n",
      "Combined PC and work-station use in Japan will jump as much as 25% annually over the next five years, according to some analysts, compared with about 10% in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Some analysts estimate the average PC costs about 50% more in Japan than the U.S\n",
      "Some analysts estimate the average PC costs about 50% more in Japan than the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In Japan, \"software is four to five years behind the U.S\n",
      "In Japan, \"software is four to five years behind the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "that some technological advances trail those in the U.S\n",
      "that some technological advances trail those in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "60s dropouts professed to scorn middle-class life\n",
      "'60s dropouts professed to scorn middle-class life\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "But Ford clearly views Jaguar as a prize worth fighting for, since the company's gilded brand image would give Ford a badly needed leg up in the high end of the luxury markets in both Europe and the U.S\n",
      "But Ford clearly views Jaguar as a prize worth fighting for, since the company's gilded brand image would give Ford a badly needed leg up in the high end of the luxury markets in both Europe and the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The most likely white knight would be Societe Generale de Belgique S.A\n",
      "The most likely white knight would be Societe Generale de Belgique S.A.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "to outflank other supercomputer competitors like Digital Equipment Corp. and International Business Machines Corp\n",
      "to outflank other supercomputer competitors like Digital Equipment Corp. and International Business Machines Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You go to any medium-sized town in the U.S\n",
      "You go to any medium-sized town in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Assets of Construction Equipment International, Houston, were sold to Essex Crane Inc\n",
      "Assets of Construction Equipment International, Houston, were sold to Essex Crane Inc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "the plant is scheduled to resume production on Nov. 20\n",
      "the plant is scheduled to resume production on Nov. 20.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Colorado National is a unit of Colorado National Bankshares Inc\n",
      "Colorado National is a unit of Colorado National Bankshares Inc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "British Aerospace PLC's Rover Group PLC subsidiary will also be able to offer the vehicles through its dealers in the U.K\n",
      "British Aerospace PLC's Rover Group PLC subsidiary will also be able to offer the vehicles through its dealers in the U.K.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The young John Gutfreund had been discovered by Billy Salomon of Salomon Bros\n",
      "The young John Gutfreund had been discovered by Billy Salomon of Salomon Bros.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bank of New England Corp said it will sell some operations and lay off 4% of its work force\n",
      "Bank of New England Corp. said it will sell some operations and lay off 4% of its work force\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Industry observers have congratulated Mr. Lang on what some call his \"courageous\" handling of Ms\n",
      "Industry observers have congratulated Mr. Lang on what some call his \"courageous\" handling of Ms.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "We've run out of places to build freeways in L.A\n",
      "We've run out of places to build freeways in L.A.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "orders are being routed through Kingsford Products unit in Louisville, Ky\n",
      "orders are being routed through Kingsford Products unit in Louisville, Ky.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The space shuttle Atlantis blasted into orbit from Cape Canaveral, Fla\n",
      "The space shuttle Atlantis blasted into orbit from Cape Canaveral, Fla.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "JAPANESE COMPANIES fare best in U.S\n",
      "JAPANESE COMPANIES fare best in U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "it will drop its $11.75-a-share, or $190 million, offer for Tesoro Petroleum Corp\n",
      "it will drop its $11.75-a-share, or $190 million, offer for Tesoro Petroleum Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "of which seven million of the shares will be offered in the U.S\n",
      "of which seven million of the shares will be offered in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The agency won't allow mushrooms that were canned or packed in brine at any Chinese plant to enter the U.S\n",
      "The agency won't allow mushrooms that were canned or packed in brine at any Chinese plant to enter the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "when he was named co-chairman of the investment-banking firm along with Howard L. Blum Jr\n",
      "when he was named co-chairman of the investment-banking firm along with Howard L. Blum Jr.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A #320 million ($508 million) British Airways PLC rights issue flopped badly -- the victim of recent market turbulence and the collapse of the buy-out bid for United Airlines' parent, UAL Corp\n",
      "#320 million ($508 million) British Airways PLC rights issue flopped badly -- the victim of recent market turbulence and the collapse of the buy-out bid for United Airlines' parent, UAL Corp\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "when it abandoned a four-year effort to market its German-built Merkur Scorpio sedan as a European luxury import in the U.S\n",
      "when it abandoned a four-year effort to market its German-built Merkur Scorpio sedan as a European luxury import in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In 1986, Baker, Nye waged a proxy fight for control of Leaseway Transportation Inc\n",
      "In 1986, Baker, Nye waged a proxy fight for control of Leaseway Transportation Inc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "In recent years, for example, Grand Metropolitan PLC of Britain acquired Heublein Inc\n",
      "In recent years, for example, Grand Metropolitan PLC of Britain acquired Heublein Inc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "About 8,000 National Union of Mineworkers members resumed their strike against De Beers Consolidated Mines Ltd\n",
      "About 8,000 National Union of Mineworkers members resumed their strike against De Beers Consolidated Mines Ltd.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bush said Washington would continue a trade embargo against Nicaragua, declaring that the Central American country poses \"an unusual and extraordinary threat\" to the security of the U.S\n",
      "Bush said Washington would continue a trade embargo against Nicaragua, declaring that the Central American country poses \"an unusual and extraordinary threat\" to the security of the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "McCaw Cellular Communications Inc. must extend its offer for LIN Broadcasting Corp\n",
      "McCaw Cellular Communications Inc. must extend its offer for LIN Broadcasting Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "MITI officials hope to avoid yet-another source of trade friction with the U.S\n",
      "MITI officials hope to avoid yet-another source of trade friction with the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "who was ousted as chairman of CBS Inc\n",
      "who was ousted as chairman of CBS Inc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "who faced rising doubt about his bid for American Airlines parent AMR Corp\n",
      "who faced rising doubt about his bid for American Airlines parent AMR Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Mad Rush\" began its life as the accompaniment to the Dalai Lama's first public address in the U.S\n",
      "Mad Rush\" began its life as the accompaniment to the Dalai Lama's first public address in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Five million shares will be offered in the U.S\n",
      "Five million shares will be offered in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "so Cap bought a hundred merchant ships more and $7 billion of loading barges, ramps, etc\n",
      "so Cap bought a hundred merchant ships more and $7 billion of loading barges, ramps, etc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Developers and money managers are looking for bargains among the thousands of financially troubled properties around the country Developers are also eyeing the real estate portfolios of major corporations.\n",
      "Some plan to pursue foreign development ventures, mostly in Europe.\n",
      "And other developers may shift from commercial to residential development in the U.S\n",
      "Developers and money managers are looking for bargains among the thousands of financially troubled properties around the country Developers are also eyeing the real estate portfolios of major corporations.\n",
      "Some plan to pursue foreign development ventures, mostly in Europe.\n",
      "And other developers may shift from commercial to residential development in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "He applauds Toyota and Nissan Motor Co\n",
      "He applauds Toyota and Nissan Motor Co.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ford Motor Co. created the Merkur nameplate in 1985 to sell its German-made touring sedans in the U.S\n",
      "Ford Motor Co. created the Merkur nameplate in 1985 to sell its German-made touring sedans in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Remaining units will be sold to the underwriters, Drexel Burnham Lambert Inc. and Kidder, Peabody & Co\n",
      "Remaining units will be sold to the underwriters, Drexel Burnham Lambert Inc. and Kidder, Peabody & Co.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "taken a Hitachi technology that is patented in the U.S\n",
      "taken a Hitachi technology that is patented in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The company's latest moves were disclosed after the Australian Stock Exchange suspended trading in shares of Qintex Australia and Qintex Ltd\n",
      "The company's latest moves were disclosed after the Australian Stock Exchange suspended trading in shares of Qintex Australia and Qintex Ltd.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "they have been only marginally profitable, if at all, in the U.S\n",
      "they have been only marginally profitable, if at all, in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "we'll release the films in the U.S\n",
      "we'll release the films in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "we'll release the films in the U.S\n",
      "we'll release the films in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Clairol was a division of Bristol-Myers Co\n",
      "Clairol was a division of Bristol-Myers Co.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A federal judge in Manhattan has entered a judgment requiring a Chicago organized crime figure to pay the government $250,000\n",
      "federal judge in Manhattan has entered a judgment requiring a Chicago organized crime figure to pay the government $250,000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The University of Toronto stepped deeper into the contest for Connaught BioSciences Inc\n",
      "The University of Toronto stepped deeper into the contest for Connaught BioSciences Inc.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "I'd slept through my only previous brush with natural disaster, a tornado 15 or so summers ago near Traverse City, Mich\n",
      "I'd slept through my only previous brush with natural disaster, a tornado 15 or so summers ago near Traverse City, Mich.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chase Manhattan Corp has exercised its option to purchase the 50-story office tower\n",
      "Chase Manhattan Corp. has exercised its option to purchase the 50-story office tower\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Trek Bicycle Corp entered the mountain-bike business in 1983\n",
      "Trek Bicycle Corp. entered the mountain-bike business in 1983\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Earlier this year, Penney abandoned another home shopping venture, Telaction Corp\n",
      "Earlier this year, Penney abandoned another home shopping venture, Telaction Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A shiny new takeover deal sparked a big rally in stock prices\n",
      "shiny new takeover deal sparked a big rally in stock prices\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A permanent smoking ban on virtually all domestic airline routes won approval from the House\n",
      "permanent smoking ban on virtually all domestic airline routes won approval from the House\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A permanent smoking ban on virtually all domestic airline routes won approval from the House, which separately sent to President Bush a nearly $67 billion fiscal 1990 bill including the first construction funds for the space station\n",
      "permanent smoking ban on virtually all domestic airline routes won approval from the House, which separately sent to President Bush a nearly $67 billion fiscal 1990 bill including the first construction funds for the space station\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sen. Pete Domenici (R., N.M.), the ranking Republican on the Senate Budget Committee, used his influence to preserve more than $132,000 in subsidies for air service to Sante Fe, N.M\n",
      "Sen. Pete Domenici (R., N.M.), the ranking Republican on the Senate Budget Committee, used his influence to preserve more than $132,000 in subsidies for air service to Sante Fe, N.M.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "But nobody else was offering them in the U.S\n",
      "But nobody else was offering them in the U.S.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Over the weekend Fossett Corp., another options trading firm, transferred the clearing accounts of about 160 traders to First Options of Chicago, a unit of Continental Bank Corp\n",
      "Over the weekend Fossett Corp., another options trading firm, transferred the clearing accounts of about 160 traders to First Options of Chicago, a unit of Continental Bank Corp.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corrected = pd.read_csv('corrected.csv')\n",
    "pdtb3 = pd.read_csv('pdtb3.csv')\n",
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit' and pdtb3.loc[i, 'DocID'] in parse_dict.keys():\n",
    "        char_start_list, char_end_list = get_list(parse_dict, pdtb3.loc[i, 'DocID'])\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Arg1_SpanList'])\n",
    "        for span in spanlist:\n",
    "            if not ((span[0] in char_start_list) and (span[1] in char_end_list)):\n",
    "                with open(main_folder  + pdtb3.loc[i, 'DocID']) as f:\n",
    "                    rawtext = f.read()\n",
    "                print(' '.join([rawtext[o[0]: o[1]] for o in spanlist]))\n",
    "                print(' '.join([rawtext[o[0]: o[1]] for o in get_span_list(corrected.loc[i,'Arg1_SpanList'])]))\n",
    "                print('\\n\\n\\n')              \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for arg2 spanlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of Arg1 error 77\n"
     ]
    }
   ],
   "source": [
    "def get_list(parse_dict, doc):\n",
    "    doc = parse_dict[doc]['sentences']\n",
    "    char_start_list = []\n",
    "    char_end_list = []\n",
    "    for sentence in doc:\n",
    "        for word in sentence['words']:\n",
    "            char_start_list.append(word[1]['CharacterOffsetBegin'])\n",
    "            char_end_list.append(word[1]['CharacterOffsetEnd'])\n",
    "    return char_start_list, char_end_list\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit' and pdtb3.loc[i, 'DocID'] in parse_dict.keys():\n",
    "        char_start_list, char_end_list = get_list(parse_dict, pdtb3.loc[i, 'DocID'])\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Arg2_SpanList'])\n",
    "        for span in spanlist:\n",
    "            if not ((span[0] in char_start_list) and (span[1] in char_end_list)):\n",
    "                count += 1\n",
    "#                 print(i, pdtb3.loc[i, 'DocID'], spanlist)\n",
    "\n",
    "print(\"the number of Arg1 error\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "doc_list = []\n",
    "for i in range(len(pdtb3)):\n",
    "    if pdtb3.loc[i, 'Relation_Type'] == 'Explicit' and pdtb3.loc[i, 'DocID'] in parse_dict.keys():\n",
    "        char_start_list, char_end_list = get_list(parse_dict, pdtb3.loc[i, 'DocID'])\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Arg2_SpanList'])\n",
    "        for span in spanlist:\n",
    "            if not ((span[0] in char_start_list) and (span[1] in char_end_list)):\n",
    "                doc_list.append(min([abs(span[0]-o) for o in char_start_list]))\n",
    "\n",
    "print(max(doc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for pdtb2 arg1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of Arg1 error 14940\n"
     ]
    }
   ],
   "source": [
    "pdtb2 = pd.read_csv('/home/pengfei/Github/pdtb2/pdtb2.csv', low_memory=False)\n",
    "gold_data_path_2 = '/home/pengfei/data/2015-2016_conll_shared_task/data/conll16st-en-03-29-16-train/pdtb-parses.json'\n",
    "parse_dict = json.loads(codecs.open(gold_data_path_2, encoding='utf-8', errors='ignore').read())\n",
    "def get_list(parse_dict, doc):\n",
    "    doc = parse_dict[doc]['sentences']\n",
    "    char_start_list = []\n",
    "    char_end_list = []\n",
    "    for sentence in doc:\n",
    "        for word in sentence['words']:\n",
    "            char_start_list.append(word[1]['CharacterOffsetBegin'])\n",
    "            char_end_list.append(word[1]['CharacterOffsetEnd'])\n",
    "    return char_start_list, char_end_list\n",
    "\n",
    "def get_docid(pdtb2, i):\n",
    "    return 'wsj_' + '{:02}'.format(pdtb2.loc[i, 'Section']) + '{:02}'.format(pdtb2.loc[i, 'FileNumber'])\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pdtb2)):\n",
    "    if pdtb2.loc[i, 'Relation'] == 'Explicit' and get_docid(pdtb2, i) in parse_dict.keys():\n",
    "        char_start_list, char_end_list = get_list(parse_dict, get_docid(pdtb2, i))\n",
    "        spanlist = get_span_list(pdtb3.loc[i, 'Arg1_SpanList'])\n",
    "        for span in spanlist:\n",
    "            if not ((span[0] in char_start_list) and (span[1] in char_end_list)):\n",
    "                count += 1\n",
    "print(\"the number of Arg1 error\", count)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the use of 'Offset' is not clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the use of 'Link' is not clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = '/home/pengfei/data/PDTB-3.0/all/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(pdtb3)):\n",
    "    pass\n",
    "#     if type(pdtb3.loc[i, 'Offset']) != float and pdtb3.loc[i, 'Relation_Type'] == 'Explicit':\n",
    "#         if pdtb3.loc[i, 'Offset'] not in pdtb3.loc[i, 'Conn_SpanList']:\n",
    "#             print(pdtb3.loc[i, 'Offset'], pdtb3.loc[i, 'Conn_SpanList'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
