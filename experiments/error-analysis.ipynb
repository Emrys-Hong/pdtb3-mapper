{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from api.api import PDTB\n",
    "import codecs\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdtb3 = PDTB('/home/pengfei/data/pdtb3/all/conll/')\n",
    "pdtb = pdtb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [json.loads(o) for o in open('/home/pengfei/Github/conll3_discourse/data/output.json').readlines()]\n",
    "\n",
    "\n",
    "def get_minus_offset(parse_dict, docid, sentid):\n",
    "    ret=0\n",
    "    for sent in parse_dict[docid]['sentences'][:sentid]:\n",
    "        ret += len(sent['words'])\n",
    "    return ret\n",
    "\n",
    "def check_if_arg(token_id, sent_id, Arg_token_list):\n",
    "    return ((sent_id, token_id) in Arg_token_list)\n",
    "\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    BACKGROUND = '\\033[7m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "def print_highlighted_prediction(predicted):\n",
    "    print('Sense: ', predicted['Sense'], '\\t', 'Type: ', predicted['Type'])\n",
    "    ret = ''\n",
    "    docid = predicted['DocID']\n",
    "    relation_sent_id = sorted(list(set([predicted['Arg1_sent_index'], predicted['Arg2_sent_index']])))\n",
    "    arg1_token_id = [(predicted['Arg1_sent_index'], o) for o in predicted['Arg1']['TokenList']]\n",
    "    arg2_token_id = [(predicted['Arg2_sent_index'], o) for o in predicted['Arg2']['TokenList']]\n",
    "    conn_token_id = [(predicted['conn_sent_offset'][0], o) for o in predicted['Connective']['TokenList']] if predicted['Type'] in ['Explicit', 'AltLex', 'AltLexC'] else []\n",
    "    for sent_id in relation_sent_id:\n",
    "        sent = pdtb.get_sent_words(docid, sent_id)\n",
    "        for token_id, word in enumerate(sent):\n",
    "            if check_if_arg(token_id, sent_id, arg1_token_id):\n",
    "                ret += color.RED + word[0] + color.END + ' '\n",
    "            elif check_if_arg(token_id, sent_id, arg2_token_id):\n",
    "                ret += color.BLUE + word[0] + color.END + ' '\n",
    "            elif check_if_arg(token_id, sent_id, conn_token_id):\n",
    "                ret += color.GREEN + word[0] + color.END + ' '\n",
    "            else:\n",
    "                ret += word[0] + ' '\n",
    "    return ret\n",
    "    \n",
    "def get_correlated_span(predicted):\n",
    "    ret = []\n",
    "    arg1_sent_id = predicted['Arg1_sent_index']\n",
    "    arg2_sent_id = predicted['Arg2_sent_index']\n",
    "    docid = predicted['DocID']\n",
    "    for i in range(len(pdtb.parse_data)):\n",
    "        if arg1_sent_id == pdtb.get_arg_sent_id(i, 'Arg1')[0]:\n",
    "            if arg2_sent_id == pdtb.get_arg_sent_id(i, 'Arg2')[0]:\n",
    "                if docid == pdtb.parse_data[i]['DocID']:\n",
    "                    ret.append(i)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22]\n",
      "Sense:  ['Expansion.Conjunction'] \t Type:  Explicit\n",
      "\u001b[91mWall\u001b[0m \u001b[91mStreet\u001b[0m \u001b[91m's\u001b[0m \u001b[91mtakeover-stock\u001b[0m \u001b[91mspeculators\u001b[0m \u001b[91m,\u001b[0m \u001b[91mor\u001b[0m \u001b[91m``\u001b[0m \u001b[91mrisk\u001b[0m \u001b[91marbitragers\u001b[0m \u001b[91m,\u001b[0m \u001b[91m''\u001b[0m \u001b[91mhad\u001b[0m \u001b[91mplaced\u001b[0m \u001b[91munusually\u001b[0m \u001b[91mlarge\u001b[0m \u001b[91mbets\u001b[0m \u001b[91mthat\u001b[0m \u001b[91ma\u001b[0m \u001b[91mtakeover\u001b[0m \u001b[91mwould\u001b[0m \u001b[91msucceed\u001b[0m \u001b[92mand\u001b[0m \u001b[94mUAL\u001b[0m \u001b[94mstock\u001b[0m \u001b[94mwould\u001b[0m \u001b[94mrise\u001b[0m . \n",
      "\n",
      "\n",
      "--------- gold relation -----------\n",
      "\n",
      "\n",
      "Relation: 46372,  Green for Connective(if any), Red for Arg1 and Blue for Arg2. \n",
      "DocID: wsj_2300,\tType: Implicit,\tSense: Contingency.Cause.Result,\n",
      "Arg1_sent_id: 22\t,\tArg2_sent_id: 22\n",
      "Wall Street 's takeover-stock speculators , or `` risk arbitragers , '' had placed unusually large bets that \u001b[91ma\u001b[0m \u001b[91mtakeover\u001b[0m \u001b[91mwould\u001b[0m \u001b[91msucceed\u001b[0m \u001b[94mand\u001b[0m \u001b[94mUAL\u001b[0m \u001b[94mstock\u001b[0m \u001b[94mwould\u001b[0m \u001b[94mrise\u001b[0m . \n",
      "\n",
      "\n",
      "Relation: 46373,  Green for Connective(if any), Red for Arg1 and Blue for Arg2. \n",
      "DocID: wsj_2300,\tType: Explicit,\tSense: Expansion.Conjunction,\n",
      "Arg1_sent_id: 22\t,\tArg2_sent_id: 22\n",
      "\u001b[91ma\u001b[0m \u001b[91mtakeover\u001b[0m \u001b[91mwould\u001b[0m \u001b[91msucceed\u001b[0m \u001b[92mand\u001b[0m \u001b[94mUAL\u001b[0m \u001b[94mstock\u001b[0m \u001b[94mwould\u001b[0m \u001b[94mrise\u001b[0m \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 5\n",
    "predicted = output[i]\n",
    "\n",
    "docid = predicted['DocID']\n",
    "arg1_sent_id = predicted['Arg1_sent_index']\n",
    "arg2_sent_id = predicted['Arg2_sent_index']\n",
    "token_minus_offset_arg1 = get_minus_offset(pdtb.parse_dict, docid, arg1_sent_id)\n",
    "token_minus_offset_arg2 = get_minus_offset(pdtb.parse_dict, docid, arg2_sent_id)\n",
    "predicted['Arg1']['TokenList'] = [o-token_minus_offset_arg1 for o in predicted['Arg1']['TokenList']]\n",
    "predicted['Arg2']['TokenList'] = [o-token_minus_offset_arg2 for o in predicted['Arg2']['TokenList']]\n",
    "if predicted['Type'] in ['Explicit', 'AltLex', 'AltLexC']:\n",
    "    predicted['conn_sent_offset'][0] = arg2_sent_id\n",
    "    conn_sent_id = predicted['conn_sent_offset'][0]\n",
    "    token_minus_offset_conn = get_minus_offset(pdtb.parse_dict, docid, conn_sent_id)\n",
    "#     print(token_minus_offset_conn)\n",
    "    predicted['Connective']['TokenList'] = [o-token_minus_offset_conn for o in predicted['Connective']['TokenList']]\n",
    "    print(predicted['Connective']['TokenList'])\n",
    "    \n",
    "print(print_highlighted_prediction(predicted))\n",
    "\n",
    "\n",
    "correlated_span = get_correlated_span(predicted)\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('--------- gold relation -----------')\n",
    "print('\\n')\n",
    "\n",
    "for c in correlated_span:\n",
    "    print(pdtb.get_highlighted_relation(c, v=True))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 2,\n",
       " 'DocID': 'wsj_2300',\n",
       " 'Arg1': {'TokenList': [8, 9, 10, 11, 12, 13, 14]},\n",
       " 'Arg2': {'TokenList': [1, 2, 3, 4, 5, 6]},\n",
       " 'Type': 'Explicit',\n",
       " 'Sense': ['Temporal.Synchronous'],\n",
       " 'Connective': {'TokenList': [0]},\n",
       " 'Arg1_sent_index': 11,\n",
       " 'Arg2_sent_index': 11,\n",
       " 'conn_sent_offset': [11],\n",
       " 'conn_name': 'when'}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
